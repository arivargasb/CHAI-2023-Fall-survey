<h4 style="text-align: center;">Stage 5 - Fairness</h4>
<style>body { font-family: Arial, sans-serif; font-size: 14px; } .table { border-collapse: collapse; width: 60%; margin: auto; } th, td { padding: 10px; text-align: center; background-color: #f2f2f2; } th:first-child, td:first-child { text-align: left; } td { font-size: 12px; } th { font-size: 12px; } h2 { font-size: 14px; }</style>

<table border="0" class="dataframe table">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>35%</th>
      <th>50%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Evaluate how data drift monitoring methods could impact bias and fairness</th>
      <td>37</td>
      <td>4.70</td>
      <td>0.57</td>
      <td>3</td>
      <td>5</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Identify who will be responsible for effective monitoring of data and AI tool</th>
      <td>37</td>
      <td>4.68</td>
      <td>0.63</td>
      <td>3</td>
      <td>5</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Consider if the impact of AI bias is monitored effectively</th>
      <td>37</td>
      <td>4.65</td>
      <td>0.48</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Consider if there are adequate mitigation measures in place for data drift</th>
      <td>37</td>
      <td>4.57</td>
      <td>0.73</td>
      <td>2</td>
      <td>5</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Consider if there are adequate mitigation measures in place for model drift</th>
      <td>37</td>
      <td>4.54</td>
      <td>0.80</td>
      <td>2</td>
      <td>5</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Identify who will be accountable for impacts of data/model breaches or data/model performance drifts</th>
      <td>37</td>
      <td>4.43</td>
      <td>0.80</td>
      <td>2</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Evaluate the risks of model performance drift in the change from small-scale pilot to full deployment</th>
      <td>37</td>
      <td>4.43</td>
      <td>0.83</td>
      <td>2</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Consider how drifts in model performance can impact model bias and fairness</th>
      <td>37</td>
      <td>4.43</td>
      <td>0.80</td>
      <td>2</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Consider what is the appropriate mix of human and algorithmic decision-making in the full deployment of the model</th>
      <td>37</td>
      <td>4.41</td>
      <td>0.80</td>
      <td>2</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Consider how impacted groups can provide feedback and how associated procedures may impact bias and fairness</th>
      <td>37</td>
      <td>4.38</td>
      <td>0.92</td>
      <td>2</td>
      <td>5</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Monitor how humans will interact with the algorithm and whether operational processes may introduce bias/issues with fairness</th>
      <td>37</td>
      <td>4.30</td>
      <td>0.74</td>
      <td>2</td>
      <td>4</td>
      <td>4</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Evaluate whether and how impacted groups will know about how they or their care interacted with AI</th>
      <td>37</td>
      <td>4.30</td>
      <td>0.85</td>
      <td>2</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Consider whether data breaches could bias the data or AI tool</th>
      <td>37</td>
      <td>4.27</td>
      <td>0.77</td>
      <td>3</td>
      <td>4</td>
      <td>4</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Ensure that there are appropriate end user feedback loops regarding the use of the algorithm</th>
      <td>37</td>
      <td>4.27</td>
      <td>0.90</td>
      <td>2</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Consider how end user training procedures may impact bias and fairness in full deployment of the model</th>
      <td>37</td>
      <td>4.19</td>
      <td>0.81</td>
      <td>3</td>
      <td>4</td>
      <td>4</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Backup (downtime) processes must be available for workflow without the health AI technology incorporated</th>
      <td>37</td>
      <td>4.03</td>
      <td>0.93</td>
      <td>2</td>
      <td>4</td>
      <td>4</td>
      <td>5</td>
    </tr>
    <tr>
      <th>Assess how continued or discontinued use of the model at specific sites may impact AI system bias and fairness</th>
      <td>37</td>
      <td>4.03</td>
      <td>0.90</td>
      <td>2</td>
      <td>4</td>
      <td>4</td>
      <td>5</td>
    </tr>
  </tbody>
</table>